"""
TEST 1: GeneraciÃ³n de Texto con Gemini 2.5 Pro
Objetivo: Probar todas las capacidades de texto de Gemini
"""

import sys
import os
sys.path.append('..')

import google.generativeai as genai
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

def test_1_respuesta_simple():
    """Test 1: Respuesta simple sin configuraciÃ³n"""
    print("\n" + "=" * 60)
    print("TEST 1: Respuesta Simple")
    print("=" * 60)
    
    genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    
    response = model.generate_content(
        "Â¿CÃ³mo puedo ayudar a un cliente que pregunta por envÃ­os?"
    )
    
    print(f"\nğŸ“ Respuesta:")
    print(response.text)
    print(f"\nâœ… Tokens usados: {response.usage_metadata}")

def test_2_con_system_instruction():
    """Test 2: Respuesta con instrucciones del sistema"""
    print("\n" + "=" * 60)
    print("TEST 2: Con System Instruction")
    print("=" * 60)
    
    client = genai.Client(api_key=Config.GEMINI_API_KEY)
    
    response = client.models.generate_content(
        model=Config.MODEL_CHAT,
        config=types.GenerateContentConfig(
            system_instruction=Config.SYSTEM_INSTRUCTION,
            temperature=Config.CHAT_TEMPERATURE
        ),
        contents="Hola, Â¿tienen envÃ­os a provincia?"
    )
    
    print(f"\nğŸ“ Respuesta con instrucciones del sistema:")
    print(response.text)

def test_3_chat_multturno():
    """Test 3: ConversaciÃ³n con mÃºltiples turnos"""
    print("\n" + "=" * 60)
    print("TEST 3: Chat Multi-Turno (Contexto)")
    print("=" * 60)
    
    client = genai.Client(api_key=Config.GEMINI_API_KEY)
    
    chat = client.chats.create(
        model=Config.MODEL_CHAT,
        config=types.GenerateContentConfig(
            system_instruction=Config.SYSTEM_INSTRUCTION
        )
    )
    
    # Turno 1
    print("\nğŸ‘¤ Usuario: Hola, vendo zapatillas")
    response1 = chat.send_message("Hola, vendo zapatillas")
    print(f"ğŸ¤– Bot: {response1.text}")
    
    # Turno 2
    print("\nğŸ‘¤ Usuario: Â¿CuÃ¡nto cuestan las deportivas?")
    response2 = chat.send_message("Â¿CuÃ¡nto cuestan las deportivas?")
    print(f"ğŸ¤– Bot: {response2.text}")
    
    # Turno 3
    print("\nğŸ‘¤ Usuario: Â¿Hacen envÃ­os?")
    response3 = chat.send_message("Â¿Hacen envÃ­os?")
    print(f"ğŸ¤– Bot: {response3.text}")
    
    # Mostrar historial
    print("\nğŸ“œ Historial del chat:")
    for i, message in enumerate(chat.get_history()):
        role = "ğŸ‘¤" if message.role == "user" else "ğŸ¤–"
        print(f"{role} {message.role}: {message.parts[0].text[:100]}...")

def test_4_streaming():
    """Test 4: Respuesta en streaming"""
    print("\n" + "=" * 60)
    print("TEST 4: Streaming de Respuesta")
    print("=" * 60)
    
    client = genai.Client(api_key=Config.GEMINI_API_KEY)
    
    print("\nğŸ‘¤ Usuario: Explica en 3 pÃ¡rrafos cÃ³mo usar WhatsApp Business")
    print("ğŸ¤– Bot (streaming): ", end="", flush=True)
    
    response = client.models.generate_content_stream(
        model=Config.MODEL_CHAT,
        contents="Explica en 3 pÃ¡rrafos cÃ³mo usar WhatsApp Business"
    )
    
    for chunk in response:
        print(chunk.text, end="", flush=True)
    
    print("\n")

def test_5_diferentes_temperaturas():
    """Test 5: Comparar diferentes temperaturas"""
    print("\n" + "=" * 60)
    print("TEST 5: ComparaciÃ³n de Temperaturas")
    print("=" * 60)
    
    client = genai.Client(api_key=Config.GEMINI_API_KEY)
    
    pregunta = "Escribe un eslogan para una tienda de ropa juvenil"
    
    for temp in [0.0, 0.5, 1.0, 1.5]:
        print(f"\nğŸŒ¡ï¸  Temperatura: {temp}")
        response = client.models.generate_content(
            model=Config.MODEL_CHAT,
            contents=pregunta,
            config=types.GenerateContentConfig(temperature=temp)
        )
        print(f"ğŸ“ Resultado: {response.text}")

def test_6_sin_pensamiento():
    """Test 6: Desactivar pensamiento para mayor velocidad"""
    print("\n" + "=" * 60)
    print("TEST 6: Sin Pensamiento (MÃ¡s RÃ¡pido)")
    print("=" * 60)
    
    client = genai.Client(api_key=Config.GEMINI_API_KEY)
    
    # Con modelo Flash y sin pensamiento
    response = client.models.generate_content(
        model=Config.MODEL_VISION,  # Flash es mÃ¡s rÃ¡pido
        contents="Â¿CuÃ¡l es el resultado de 2+2?",
        config=types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig(thinking_budget=0)
        )
    )
    
    print(f"\nğŸ“ Respuesta rÃ¡pida: {response.text}")

def main():
    """Ejecutar todos los tests"""
    print("\n" + "=" * 60)
    print("  ğŸ§ª SUITE DE TESTS - GENERACIÃ“N DE TEXTO")
    print("=" * 60)
    print(f"Modelo: {Config.MODEL_CHAT}")
    print(f"API Key: {'âœ… Configurada' if Config.GEMINI_API_KEY else 'âŒ NO configurada'}")
    
    if not Config.GEMINI_API_KEY:
        print("\nâŒ ERROR: Configura GEMINI_API_KEY en el archivo .env")
        return
    
    try:
        # Ejecutar tests
        test_1_respuesta_simple()
        input("\nPresiona Enter para continuar al siguiente test...")
        
        test_2_con_system_instruction()
        input("\nPresiona Enter para continuar al siguiente test...")
        
        test_3_chat_multturno()
        input("\nPresiona Enter para continuar al siguiente test...")
        
        test_4_streaming()
        input("\nPresiona Enter para continuar al siguiente test...")
        
        test_5_diferentes_temperaturas()
        input("\nPresiona Enter para continuar al siguiente test...")
        
        test_6_sin_pensamiento()
        
        print("\n" + "=" * 60)
        print("  âœ… TODOS LOS TESTS COMPLETADOS")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
